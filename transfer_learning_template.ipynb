{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "md-x1taQ8yGx"
      },
      "source": [
        "## Transfer Learning for Computer Vision Tutorial\n",
        "\n",
        "**Inspired by**: [Sasank Chilamkurthy](https://chsasank.github.io)\n",
        "\n",
        "**Modified by**: \n",
        "- [win7](https://github.com/win7) at October 2023\n",
        "- [win7](https://github.com/win7) at July 2023\n",
        "\n",
        "In this tutorial, you will learn how to train a convolutional neural network for\n",
        "image classification using transfer learning. You can read more about the transfer\n",
        "learning at [cs231n notes](https://cs231n.github.io/transfer-learning/)_\n",
        "\n",
        "Quoting these notes,\n",
        "\n",
        "    In practice, very few people train an entire Convolutional Network\n",
        "    from scratch (with random initialization), because it is relatively\n",
        "    rare to have a dataset of sufficient size. Instead, it is common to\n",
        "    pretrain a ConvNet on a very large dataset (e.g. ImageNet, which\n",
        "    contains 1.2 million images with 1000 categories), and then use the\n",
        "    ConvNet either as an initialization or a fixed feature extractor for\n",
        "    the task of interest.\n",
        "\n",
        "These two major transfer learning scenarios look as follows:\n",
        "\n",
        "-  **Fine-tuning the convnet**: Instead of random initialization, we\n",
        "   initialize the network with a pretrained network, like the one that is\n",
        "   trained on imagenet 1000 dataset. Rest of the training looks as\n",
        "   usual.\n",
        "-  **ConvNet as fixed feature extractor**: Here, we will freeze the weights\n",
        "   for all of the network except that of the final fully connected\n",
        "   layer. This last fully connected layer is replaced with a new one\n",
        "   with random weights and only this layer is trained.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Transfer Learning Summary\n",
        "\n",
        "- Use a pre-trained model out-of-the-box (good if a model already exists for your problem).\n",
        "\n",
        "- Use a pre-trained model as a **feature extractor** (good if you want to adapt a pre-trained model for a specific problem).\n",
        "\n",
        "- **Fine-tune** a pre-trained model (same as 2 but generally yields better results, although at more computational cost)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0K8D2yZ8yGy",
        "notebookRunGroups": {
          "groupValue": "1"
        },
        "outputId": "f726af03-30dd-455c-e9ef-0d60a6fab390"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autotime extension is already loaded. To reload it, use:\n",
            "  %reload_ext autotime\n",
            "time: 4.79 ms (started: 2023-07-12 10:32:50 -05:00)\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function, division\n",
        "from PIL import Image, ImageStat\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data.sampler import WeightedRandomSampler\n",
        "from torchsampler import ImbalancedDatasetSampler\n",
        "from torch.optim import lr_scheduler\n",
        "from tempfile import TemporaryDirectory\n",
        "from tqdm import tqdm\n",
        "\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import memory_profiler  # conda install -c anaconda memory_profiler\n",
        "import neptune\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import sys\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision\n",
        "\n",
        "# cudnn.benchmark = True\n",
        "# plt.ion()   # interactive mode\n",
        "\n",
        "%matplotlib inline\n",
        "%load_ext autotime"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88IWH2bxRwS0",
        "notebookRunGroups": {
          "groupValue": "1"
        },
        "outputId": "a6b5436a-3f34-4064-914c-9f3a1e7a9a92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 7.48 ms (started: 2023-07-12 10:32:50 -05:00)\n"
          ]
        }
      ],
      "source": [
        "def move_split(df, type): # change this function according your dataset\n",
        "    if not os.path.isdir(\"dataset\"):\n",
        "        os.makedirs(\"dataset\")\n",
        "\n",
        "        for item in np.unique(df.iloc[:, -1]):\n",
        "            os.makedirs(\"dataset/train/class_{}\".format(item))\n",
        "            os.makedirs(\"dataset/val/class_{}\".format(item))\n",
        "    \n",
        "    for index, row in tqdm(df.iterrows()):\n",
        "        s = \"source/train/{}_{}.jpg\".format(row[\"ID\"], row[\"location\"])\n",
        "        t = \"dataset/{}/class_{}\".format(type, row[\"level\"])\n",
        "        shutil.copy(s, t)\n",
        "\n",
        "def set_parameter_requires_grad(model, feature_extract):\n",
        "    if feature_extract:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "# set initialize weight for custom model\n",
        "def init_weights(m):\n",
        "    if isinstance(m, torch.nn.Linear):\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        m.bias.data.fill_(0.01)\n",
        "\n",
        "def classifier_model(num_ftrs, num_classes, init_weight=False):\n",
        "    # Custom model\n",
        "    \"\"\" torch.nn.Conv2d(in_channels=8, out_channels=3, kernel_size=(3, 3), padding=1),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.MaxPool2d((2, 2)),\n",
        "    torch.nn.Conv2d(in_channels=3, out_channels=2, kernel_size=(3, 3), padding=1),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.MaxPool2d((2, 2)),\n",
        "    torch.nn.Flatten(), \"\"\"\n",
        "\n",
        "    \"\"\" model = torch.nn.Sequential(torch.nn.Linear(num_ftrs, 128),\n",
        "                                torch.nn.ReLU(),\n",
        "\n",
        "                                torch.nn.Linear(128, 64),\n",
        "                                torch.nn.ReLU(),\n",
        "                                torch.nn.Dropout(0.5),\n",
        "\n",
        "                                torch.nn.Linear(64, num_classes)) \"\"\"\n",
        "    \n",
        "    model = torch.nn.Sequential(torch.nn.Linear(num_ftrs, 1024),\n",
        "                                torch.nn.Mish(),\n",
        "\n",
        "                                torch.nn.Linear(1024, 512),\n",
        "                                torch.nn.Mish(),\n",
        "\n",
        "                                torch.nn.Linear(512, 128),\n",
        "                                torch.nn.Mish(),\n",
        "                                torch.nn.Dropout(0.5),\n",
        "\n",
        "                                torch.nn.Linear(128, num_classes))\n",
        "    \n",
        "    if init_weight:\n",
        "        model.apply(init_weights)\n",
        "    return model\n",
        "\n",
        "def initialize_model(model_name, num_classes, feature_extract):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    # variables is model specific.\n",
        "    model = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"alexnet\":\n",
        "        model = models.alexnet(weights=\"IMAGENET1K_V1\")\n",
        "        set_parameter_requires_grad(model, feature_extract)\n",
        "        num_ftrs = model.classifier[6].in_features\n",
        "        model.classifier[6] = classifier_model(num_ftrs, num_classes, init_weight=True) # nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"convnext_large\":\n",
        "        model = models.convnext_large(weights=\"IMAGENET1K_V1\")\n",
        "        set_parameter_requires_grad(model, feature_extract)\n",
        "        num_ftrs = model.classifier[2].in_features\n",
        "        model.classifier[2] = classifier_model(num_ftrs, num_classes, init_weight=True) # nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet201\":\n",
        "        model = models.densenet201(weights=\"IMAGENET1K_V1\")\n",
        "        set_parameter_requires_grad(model, feature_extract)\n",
        "        num_ftrs = model.classifier.in_features\n",
        "        model.classifier = classifier_model(num_ftrs, num_classes, init_weight=True) # nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"efficientnet_v2_l\":\n",
        "        model = models.efficientnet_v2_l(weights=\"IMAGENET1K_V1\")\n",
        "        set_parameter_requires_grad(model, feature_extract)\n",
        "        num_ftrs = model.classifier[1].in_features\n",
        "        model.classifier[1] = classifier_model(num_ftrs, num_classes, init_weight=True) # nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 480\n",
        "\n",
        "    elif model_name == \"googlenet\":\n",
        "        model = models.googlenet(weights=\"IMAGENET1K_V1\")\n",
        "        set_parameter_requires_grad(model, feature_extract)\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = classifier_model(num_ftrs, num_classes, init_weight=True) # nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 384\n",
        "\n",
        "    elif model_name == \"inception_v3\":\n",
        "        model = models.inception_v3(weights=\"IMAGENET1K_V1\")\n",
        "        set_parameter_requires_grad(model, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model.AuxLogits.fc.in_features\n",
        "        model.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "        \"\"\" set_parameter_requires_grad(model, feature_extract)\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = classifier_model(num_ftrs, num_classes, init_weight=True) # nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 299 \"\"\"\n",
        "\n",
        "    elif model_name == \"mnasnet1_3\":\n",
        "        model = models.mnasnet1_3(weights=\"IMAGENET1K_V1\")\n",
        "        set_parameter_requires_grad(model, feature_extract)\n",
        "        num_ftrs = model.classifier[1].in_features\n",
        "        model.classifier[1] = classifier_model(num_ftrs, num_classes, init_weight=True) # nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"maxvit_t\":\n",
        "        model = models.maxvit_t(weights=\"IMAGENET1K_V1\")\n",
        "        set_parameter_requires_grad(model, feature_extract)\n",
        "        num_ftrs = model.classifier[5].in_features\n",
        "        model.classifier[5] = classifier_model(num_ftrs, num_classes, init_weight=True) # nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"mobilenet_v3_large\":\n",
        "        model = models.mobilenet_v3_large(weights=\"IMAGENET1K_V2\")\n",
        "        set_parameter_requires_grad(model, feature_extract)\n",
        "        num_ftrs = model.classifier[3].in_features\n",
        "        model.classifier[3] = classifier_model(num_ftrs, num_classes, init_weight=True) # nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"regnet_y_128gf\":\n",
        "        model = models.regnet_y_128gf(weights=\"IMAGENET1K_SWAG_E2E_V1\")\n",
        "        set_parameter_requires_grad(model, feature_extract)\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = classifier_model(num_ftrs, num_classes, init_weight=True) # nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 384\n",
        "\n",
        "    elif model_name == \"resnext101_64x4d\":\n",
        "        model = models.resnext101_64x4d(weights=\"IMAGENET1K_V1\")\n",
        "        set_parameter_requires_grad(model, feature_extract)\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = classifier_model(num_ftrs, num_classes, init_weight=True) # nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"resnet152\":\n",
        "        model = models.resnet152(weights=\"IMAGENET1K_V2\")\n",
        "        set_parameter_requires_grad(model, feature_extract)\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = classifier_model(num_ftrs, num_classes, init_weight=True) # # nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"shufflenet_v2_x2_0\":\n",
        "        model = models.shufflenet_v2_x2_0(weights=\"IMAGENET1K_V1\")\n",
        "        set_parameter_requires_grad(model, feature_extract)\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = classifier_model(num_ftrs, num_classes, init_weight=True) # # nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet1_1\":\n",
        "        model = models.squeezenet1_1(weights=\"IMAGENET1K_V1\")\n",
        "        set_parameter_requires_grad(model, feature_extract)\n",
        "        model.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1, 1), stride=(1, 1))\n",
        "        model.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"swin_v2_b\":\n",
        "        model = models.swin_v2_b(weights=\"IMAGENET1K_V1\")\n",
        "        set_parameter_requires_grad(model, feature_extract)\n",
        "        num_ftrs = model.head.in_features\n",
        "        model.head = classifier_model(num_ftrs, num_classes, init_weight=True) # # nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 256\n",
        "\n",
        "    elif model_name == \"vgg19\":\n",
        "        model = models.vgg19_bn(weights=\"IMAGENET1K_V1\")\n",
        "        set_parameter_requires_grad(model, feature_extract)\n",
        "        num_ftrs = model.classifier[6].in_features\n",
        "        model.classifier[6] = classifier_model(num_ftrs, num_classes, init_weight=True) # nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vit_h_14\":\n",
        "        model = models.vit_h_14(weights=\"IMAGENET1K_SWAG_E2E_V1\")\n",
        "        set_parameter_requires_grad(model, feature_extract)\n",
        "        num_ftrs = model.heads.head.in_features\n",
        "        model.heads.head = classifier_model(num_ftrs, num_classes, init_weight=True) # nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 518\n",
        "\n",
        "    elif model_name == \"wide_resnet101_2\":\n",
        "        model = models.wide_resnet101_2(weights=\"IMAGENET1K_V2\")\n",
        "        set_parameter_requires_grad(model, feature_extract)\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = classifier_model(num_ftrs, num_classes, init_weight=True) # nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    # ---    \n",
        "    elif model_name == \"resnet50\":\n",
        "        model = models.resnet50(weights=\"IMAGENET1K_V2\")\n",
        "        set_parameter_requires_grad(model, feature_extract)\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = classifier_model(num_ftrs, num_classes, init_weight=True) # nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        weights = models.Inception_V3_Weights.IMAGENET1K_V1 #\n",
        "        model = models.inception_v3(weights=weights, progress=True)\n",
        "        set_parameter_requires_grad(model, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model.AuxLogits.fc.in_features\n",
        "        model.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model, input_size\n",
        "\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "def train_model(run, model, device, dataloaders, dataset_sizes, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    # Create a temporary directory to save training checkpoints\n",
        "    with TemporaryDirectory() as tempdir:\n",
        "        best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
        "\n",
        "        torch.save(model.state_dict(), best_model_params_path)\n",
        "        best_acc = 0.0\n",
        "\n",
        "        loop_obj = tqdm(range(num_epochs))\n",
        "        for epoch in loop_obj:\n",
        "            # print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "            # print('-' * 10)\n",
        "            loop_obj.set_description(f\"Epoch: {epoch + 1}\")\n",
        "            run[\"params/epochs\"] = epoch + 1\n",
        "\n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in [\"train\", \"val\"]:\n",
        "                if phase == 'train':\n",
        "                    model.train()  # Set model to training mode\n",
        "                else:\n",
        "                    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "\n",
        "                # Iterate over data.\n",
        "                for inputs, labels in dataloaders[phase]:\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    # zero the parameter gradients\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # forward\n",
        "                    # track history if only in train\n",
        "                    with torch.set_grad_enabled(phase == \"train\"):\n",
        "                        outputs = model(inputs)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                        # backward + optimize only if in training phase\n",
        "                        if phase == \"train\":\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    # statistics\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "                if phase == \"train\":\n",
        "                    scheduler.step()\n",
        "\n",
        "                epoch_loss = running_loss / dataset_sizes[phase]\n",
        "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "                # print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "                loop_obj.set_postfix_str(f\"{phase}, Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "                run[\"{}/accuracy\".format(phase)].append(epoch_acc)\n",
        "                run[\"{}/loss\".format(phase)].append(epoch_loss)\n",
        "\n",
        "                if phase == \"train\":\n",
        "                    train_accuracies.append(epoch_acc)\n",
        "                    train_losses.append(epoch_loss)\n",
        "                else:\n",
        "                    val_accuracies.append(epoch_acc)\n",
        "                    val_losses.append(epoch_loss)\n",
        "\n",
        "                # deep copy the model\n",
        "                if phase == \"val\" and epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "        print(f'Best val Acc: {best_acc:4f}')\n",
        "        run[\"train/runtime\"] = time_elapsed // 60\n",
        "\n",
        "        # load best model weights\n",
        "        model.load_state_dict(torch.load(best_model_params_path))\n",
        "    return model, train_accuracies, train_losses, val_accuracies, val_losses\n",
        "\n",
        "def visualize_model(model, num_images=6): # no used\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders[\"val\"]):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis(\"off\")\n",
        "                ax.set_title(f\"predicted: {class_names[preds[j]]}\")\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "def show_results(train_losses, val_losses, train_accuracies, val_accuracies):# no used\n",
        "    train_accuracies_ = [h.cpu().numpy() for h in train_accuracies]\n",
        "    val_accuracies_ = [h.cpu().numpy() for h in val_accuracies]\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14,4))\n",
        "    ax1, ax2 = axes\n",
        "    ax1.plot(train_losses, label=\"train\")\n",
        "    ax1.plot(val_losses, label=\"val\")\n",
        "    ax1.set_xlabel(\"Epoch\"); ax1.set_ylabel(\"Loss\")\n",
        "    ax1.grid()\n",
        "    ax2.plot(train_accuracies_, label=\"train\")\n",
        "    ax2.plot(val_accuracies_, label=\"val\")\n",
        "    ax2.set_xlabel(\"Epoch\"); ax2.set_ylabel(\"Accuracy\")\n",
        "    ax2.grid()\n",
        "    for ax in axes: ax.legend()\n",
        "\n",
        "def get_predictions(model_ft, dataloaders, type_data):\n",
        "    labels = []\n",
        "    predictions = []\n",
        "    predictions_proba = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_x_test, batch_y_test in dataloaders[type_data]:\n",
        "            batch_x_test = batch_x_test.to(device).to(torch.float32)\n",
        "            batch_y_test = batch_y_test.to(device).to(torch.int64)\n",
        "\n",
        "            batch_test_predictions = model_ft(batch_x_test)\n",
        "            # batch_test_predictions = model_conv(batch_x_test)\n",
        "\n",
        "            batch_test_predictions = torch.nn.functional.softmax(batch_test_predictions, dim=-1)\n",
        "            predictions_proba.append(batch_test_predictions)\n",
        "            # print(batch_test_predictions)\n",
        "\n",
        "            batch_test_predictions = batch_test_predictions.max(dim=1).indices\n",
        "            # print(batch_test_predictions)\n",
        "\n",
        "            labels.append(batch_y_test)\n",
        "            predictions.append(batch_test_predictions)\n",
        "\n",
        "    labels = torch.cat(labels, dim=0)\n",
        "    predictions = torch.cat(predictions, dim=0)\n",
        "    predictions_proba = torch.cat(predictions_proba, dim=0)\n",
        "\n",
        "    labels = labels.cpu().numpy()\n",
        "    predictions = predictions.cpu().numpy()\n",
        "    predictions_proba = predictions_proba.cpu().numpy()\n",
        "    return labels, predictions, predictions_proba\n",
        "\n",
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "def get_data_transforms(option, input_size, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
        "    list_data_transforms = [\n",
        "        # transforms 0\n",
        "        {\n",
        "            \"train\": transforms.Compose([\n",
        "                transforms.RandomResizedCrop(input_size),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std)\n",
        "            ]),\n",
        "            \"val\": transforms.Compose([\n",
        "                transforms.Resize(input_size),\n",
        "                transforms.CenterCrop(input_size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std)\n",
        "            ]),\n",
        "        },\n",
        "        # transforms 1\n",
        "        {\n",
        "            \"train\": transforms.Compose([\n",
        "                transforms.RandomResizedCrop(input_size),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std)\n",
        "            ]),\n",
        "            \"val\": transforms.Compose([\n",
        "                transforms.Resize(input_size),\n",
        "                transforms.CenterCrop(input_size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std)\n",
        "            ]),\n",
        "        },\n",
        "        # transforms 2\n",
        "        {\n",
        "            \"train\": transforms.Compose([\n",
        "                transforms.Resize(400),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.CenterCrop(input_size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std)\n",
        "            ]),\n",
        "            \"val\": transforms.Compose([\n",
        "                transforms.Resize(input_size),\n",
        "                transforms.CenterCrop(input_size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std)\n",
        "            ]),\n",
        "        },\n",
        "        # transforms 3\n",
        "        {\n",
        "            \"train\": transforms.Compose([\n",
        "                transforms.Resize(400),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.CenterCrop(input_size),\n",
        "                transforms.RandomRotation(degrees=45),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std)\n",
        "            ]),\n",
        "            \"val\": transforms.Compose([\n",
        "                transforms.Resize(input_size),\n",
        "                transforms.CenterCrop(input_size),\n",
        "                transforms.RandomRotation(degrees=20),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std)\n",
        "            ]),\n",
        "        }\n",
        "    ]\n",
        "    data_transforms = list_data_transforms[option]\n",
        "    return data_transforms\n",
        "\n",
        "def get_optimizer(model, option):\n",
        "    optimizers = [\n",
        "        optim.Adadelta(model.parameters(), lr=1.0),             # 0\n",
        "        optim.Adagrad(model.parameters(), lr=0.01),             # 1\n",
        "        optim.Adam(model.parameters(), lr=0.001),               # 2\n",
        "        optim.AdamW(model.parameters(), lr=0.001),              # 3\n",
        "        optim.SparseAdam(model.parameters(), lr=0.001),         # 4, SparseAdam does not support dense gradients, please consider Adam instead\n",
        "        optim.Adamax(model.parameters(), lr=0.002),             # 5\n",
        "        optim.ASGD(model.parameters(), lr=0.01),                # 6\n",
        "        optim.LBFGS(model.parameters(), lr=1),                  # 7, more cost\n",
        "        optim.NAdam(model.parameters(), lr=0.002),              # 8\n",
        "        optim.RAdam(model.parameters(), lr=0.001),              # 9   \n",
        "        optim.RMSprop(model.parameters(), lr=0.01),             # 10\n",
        "        optim.Rprop(model.parameters(), lr=0.01),               # 11\n",
        "        optim.SGD(model.parameters(), lr=0.001, momentum=0.7)   # 12\n",
        "    ]\n",
        "    return optimizers[option]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1RAC0vLJGeNg"
      },
      "source": [
        "### Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "zWISQyq-NsgY",
        "outputId": "8650caa7-d10f-4e87-9606-41a4404a345e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>location</th>\n",
              "      <th>level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>d3d9446802a44259755d38e6d163e820</td>\n",
              "      <td>left</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d3d9446802a44259755d38e6d163e820</td>\n",
              "      <td>right</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c51ce410c124a10e0db5e4b97fc2af39</td>\n",
              "      <td>left</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c51ce410c124a10e0db5e4b97fc2af39</td>\n",
              "      <td>right</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9bf31c7ff062936a96d3c8bd1f8f2ff3</td>\n",
              "      <td>left</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24583</th>\n",
              "      <td>7dc5ece165388748790d8170245197ed</td>\n",
              "      <td>right</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24584</th>\n",
              "      <td>e3c216d521607da146fa23d65cfcc6b6</td>\n",
              "      <td>left</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24585</th>\n",
              "      <td>e3c216d521607da146fa23d65cfcc6b6</td>\n",
              "      <td>right</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24586</th>\n",
              "      <td>54d9ee4df2caa006b994d148f23a9b10</td>\n",
              "      <td>left</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24587</th>\n",
              "      <td>54d9ee4df2caa006b994d148f23a9b10</td>\n",
              "      <td>right</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24588 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     ID location  level\n",
              "0      d3d9446802a44259755d38e6d163e820     left      0\n",
              "1      d3d9446802a44259755d38e6d163e820    right      0\n",
              "2      c51ce410c124a10e0db5e4b97fc2af39     left      0\n",
              "3      c51ce410c124a10e0db5e4b97fc2af39    right      0\n",
              "4      9bf31c7ff062936a96d3c8bd1f8f2ff3     left      1\n",
              "...                                 ...      ...    ...\n",
              "24583  7dc5ece165388748790d8170245197ed    right      0\n",
              "24584  e3c216d521607da146fa23d65cfcc6b6     left      0\n",
              "24585  e3c216d521607da146fa23d65cfcc6b6    right      0\n",
              "24586  54d9ee4df2caa006b994d148f23a9b10     left      0\n",
              "24587  54d9ee4df2caa006b994d148f23a9b10    right      0\n",
              "\n",
              "[24588 rows x 3 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 45.9 ms (started: 2023-07-12 10:32:50 -05:00)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"source/train.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0RuA0yyITq7",
        "outputId": "df041e05-f3eb-4761-f474-16feb78812bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    18057\n",
              "1     6531\n",
              "Name: level, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 3.06 ms (started: 2023-07-12 10:32:51 -05:00)\n"
          ]
        }
      ],
      "source": [
        "# count classes\n",
        "df[\"level\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>d3d9446802a44259755d38e6d163e820</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d3d9446802a44259755d38e6d163e820</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c51ce410c124a10e0db5e4b97fc2af39</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c51ce410c124a10e0db5e4b97fc2af39</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9bf31c7ff062936a96d3c8bd1f8f2ff3</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24583</th>\n",
              "      <td>7dc5ece165388748790d8170245197ed</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24584</th>\n",
              "      <td>e3c216d521607da146fa23d65cfcc6b6</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24585</th>\n",
              "      <td>e3c216d521607da146fa23d65cfcc6b6</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24586</th>\n",
              "      <td>54d9ee4df2caa006b994d148f23a9b10</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24587</th>\n",
              "      <td>54d9ee4df2caa006b994d148f23a9b10</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24588 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     ID location\n",
              "0      d3d9446802a44259755d38e6d163e820     left\n",
              "1      d3d9446802a44259755d38e6d163e820    right\n",
              "2      c51ce410c124a10e0db5e4b97fc2af39     left\n",
              "3      c51ce410c124a10e0db5e4b97fc2af39    right\n",
              "4      9bf31c7ff062936a96d3c8bd1f8f2ff3     left\n",
              "...                                 ...      ...\n",
              "24583  7dc5ece165388748790d8170245197ed    right\n",
              "24584  e3c216d521607da146fa23d65cfcc6b6     left\n",
              "24585  e3c216d521607da146fa23d65cfcc6b6    right\n",
              "24586  54d9ee4df2caa006b994d148f23a9b10     left\n",
              "24587  54d9ee4df2caa006b994d148f23a9b10    right\n",
              "\n",
              "[24588 rows x 2 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 17.3 ms (started: 2023-07-12 10:32:51 -05:00)\n"
          ]
        }
      ],
      "source": [
        "df_X = df.iloc[:, :-1]\n",
        "df_X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24583</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24584</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24585</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24586</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24587</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24588 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       level\n",
              "0          0\n",
              "1          0\n",
              "2          0\n",
              "3          0\n",
              "4          1\n",
              "...      ...\n",
              "24583      0\n",
              "24584      0\n",
              "24585      0\n",
              "24586      0\n",
              "24587      0\n",
              "\n",
              "[24588 rows x 1 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 17.6 ms (started: 2023-07-12 10:32:51 -05:00)\n"
          ]
        }
      ],
      "source": [
        "df_y = df.iloc[:, -1:]\n",
        "df_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(19670, 4918, 19670, 4918)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 95.4 ms (started: 2023-07-12 10:32:51 -05:00)\n"
          ]
        }
      ],
      "source": [
        "# df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.2, random_state=42, stratify=df_y)\n",
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>location</th>\n",
              "      <th>level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>3dc4876f3f08201c7c76cb71fa1da439</td>\n",
              "      <td>left</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16271</th>\n",
              "      <td>dd24bf1f94c244e91a4a783a50f36b6f</td>\n",
              "      <td>right</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7110</th>\n",
              "      <td>a0b173044f2019316bebc411696e7d35</td>\n",
              "      <td>left</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12530</th>\n",
              "      <td>d79bc606792288b59c64959c6bcbf5d5</td>\n",
              "      <td>left</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8871</th>\n",
              "      <td>b0263bc40e0ff50f481b85a968c30ac1</td>\n",
              "      <td>right</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13812</th>\n",
              "      <td>614794dbe82384e43122cc92e6a66f6f</td>\n",
              "      <td>left</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16999</th>\n",
              "      <td>252a3893179658de41f437d975468205</td>\n",
              "      <td>right</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9356</th>\n",
              "      <td>34f9679482b481012016f1f5c8b977f0</td>\n",
              "      <td>left</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3042</th>\n",
              "      <td>66fae5b05c0f64c4d2bdcdf1ad85f7b2</td>\n",
              "      <td>left</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10303</th>\n",
              "      <td>04e35ab54388b691735c8b4231d387a1</td>\n",
              "      <td>right</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19670 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     ID location  level\n",
              "328    3dc4876f3f08201c7c76cb71fa1da439     left      0\n",
              "16271  dd24bf1f94c244e91a4a783a50f36b6f    right      0\n",
              "7110   a0b173044f2019316bebc411696e7d35     left      0\n",
              "12530  d79bc606792288b59c64959c6bcbf5d5     left      0\n",
              "8871   b0263bc40e0ff50f481b85a968c30ac1    right      0\n",
              "...                                 ...      ...    ...\n",
              "13812  614794dbe82384e43122cc92e6a66f6f     left      1\n",
              "16999  252a3893179658de41f437d975468205    right      0\n",
              "9356   34f9679482b481012016f1f5c8b977f0     left      0\n",
              "3042   66fae5b05c0f64c4d2bdcdf1ad85f7b2     left      0\n",
              "10303  04e35ab54388b691735c8b4231d387a1    right      0\n",
              "\n",
              "[19670 rows x 3 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 6.15 ms (started: 2023-07-12 10:32:51 -05:00)\n"
          ]
        }
      ],
      "source": [
        "df_train = X_train.copy()\n",
        "df_train[\"level\"] = y_train\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>location</th>\n",
              "      <th>level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11916</th>\n",
              "      <td>8bc96a461bd0ce6616f30b9383b7427d</td>\n",
              "      <td>left</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23962</th>\n",
              "      <td>080261e4427a081fc6e637b654f590ee</td>\n",
              "      <td>left</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8273</th>\n",
              "      <td>d16c8f18bdee715020ec90b5ec04e9d4</td>\n",
              "      <td>right</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2103</th>\n",
              "      <td>62e7f2e090fe150ef8deb4466fdc81b3</td>\n",
              "      <td>right</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5340</th>\n",
              "      <td>2bdfb48c5fa7d2344b71ef45c8a7d31c</td>\n",
              "      <td>left</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16463</th>\n",
              "      <td>65742cafb273e12fc7bb968b5fca065e</td>\n",
              "      <td>right</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7593</th>\n",
              "      <td>8e887cf8e64ab8e7173701a979476567</td>\n",
              "      <td>right</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9146</th>\n",
              "      <td>5939cbe46f1512291125700ee2e7236a</td>\n",
              "      <td>left</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>708</th>\n",
              "      <td>36a1694bce9815b7e38a9dad05ad42e0</td>\n",
              "      <td>left</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4084</th>\n",
              "      <td>52fc2aee802efbad698503d28ebd3a1f</td>\n",
              "      <td>left</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4918 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     ID location  level\n",
              "11916  8bc96a461bd0ce6616f30b9383b7427d     left      1\n",
              "23962  080261e4427a081fc6e637b654f590ee     left      0\n",
              "8273   d16c8f18bdee715020ec90b5ec04e9d4    right      0\n",
              "2103   62e7f2e090fe150ef8deb4466fdc81b3    right      0\n",
              "5340   2bdfb48c5fa7d2344b71ef45c8a7d31c     left      1\n",
              "...                                 ...      ...    ...\n",
              "16463  65742cafb273e12fc7bb968b5fca065e    right      1\n",
              "7593   8e887cf8e64ab8e7173701a979476567    right      0\n",
              "9146   5939cbe46f1512291125700ee2e7236a     left      0\n",
              "708    36a1694bce9815b7e38a9dad05ad42e0     left      0\n",
              "4084   52fc2aee802efbad698503d28ebd3a1f     left      0\n",
              "\n",
              "[4918 rows x 3 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 17.7 ms (started: 2023-07-12 10:32:51 -05:00)\n"
          ]
        }
      ],
      "source": [
        "df_test = X_test.copy()\n",
        "df_test[\"level\"] = y_test\n",
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9nkO1ifIesW",
        "outputId": "ff8f38b5-8547-48a9-cb3e-402a56946b66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 8.92 ms (started: 2023-07-12 10:32:51 -05:00)\n"
          ]
        }
      ],
      "source": [
        "# move image into train and test folder\n",
        "# move_split(df_train, \"train\") () # uncomment this to move the images\n",
        "# move_split(df_test, \"val\") # uncomment this to move the images"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg-eScWwJgsN"
      },
      "source": [
        "### Initialize and Reshape the networks"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4b0blWotqRIV"
      },
      "source": [
        "Set Model Parameters’ .requires_grad attribute\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "\n",
        "This helper function sets the ``.requires_grad`` attribute of the\n",
        "parameters in the model to False when we are feature extracting. By\n",
        "default, when we load a pretrained model all of the parameters have\n",
        "``.requires_grad=True``, which is fine if we are training from scratch\n",
        "or finetuning. However, if we are feature extracting and only want to\n",
        "compute gradients for the newly initialized layer then we want all of\n",
        "the other parameters to not require gradients. This will make more sense\n",
        "later."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JWmsZnoOKJys"
      },
      "source": [
        "#### Details"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qSQWr6_PqRIW"
      },
      "source": [
        "Now to the most interesting part. Here is where we handle the reshaping\n",
        "of each network. Note, this is not an automatic procedure and is unique\n",
        "to each model. Recall, the final layer of a CNN model, which is often\n",
        "times an FC layer, has the same number of nodes as the number of output\n",
        "classes in the dataset. Since all of the models have been pretrained on\n",
        "Imagenet, they all have output layers of size 1000, one node for each\n",
        "class. The goal here is to reshape the last layer to have the same\n",
        "number of inputs as before, AND to have the same number of outputs as\n",
        "the number of classes in the dataset. In the following sections we will\n",
        "discuss how to alter the architecture of each model individually. But\n",
        "first, there is one important detail regarding the difference between\n",
        "finetuning and feature-extraction.\n",
        "\n",
        "When feature extracting, we only want to update the parameters of the\n",
        "last layer, or in other words, we only want to update the parameters for\n",
        "the layer(s) we are reshaping. Therefore, we do not need to compute the\n",
        "gradients of the parameters that we are not changing, so for efficiency\n",
        "we set the .requires_grad attribute to False. This is important because\n",
        "by default, this attribute is set to True. Then, when we initialize the\n",
        "new layer and by default the new parameters have ``.requires_grad=True``\n",
        "so only the new layer’s parameters will be updated. When we are\n",
        "finetuning we can leave all of the .required_grad’s set to the default\n",
        "of True.\n",
        "\n",
        "Finally, notice that inception_v3 requires the input size to be\n",
        "(299,299), whereas all of the other models expect (224,224).\n",
        "\n",
        "```python \n",
        "model = models.alexnet(weights=\"IMAGENET1K_V1\")\n",
        "\"\"\"\n",
        "(classifier): Sequential(\n",
        "    (0): Dropout(p=0.5, inplace=False)\n",
        "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
        "    (2): ReLU(inplace=True)\n",
        "    (3): Dropout(p=0.5, inplace=False)\n",
        "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
        "    (5): ReLU(inplace=True)\n",
        "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
        ")\n",
        "crop_size=[224]\n",
        "\"\"\"\n",
        "\n",
        "model = models.convnext_large(weights=\"IMAGENET1K_V1\")\n",
        "\"\"\"\n",
        "(classifier): Sequential(\n",
        "    (0): LayerNorm2d((1536,), eps=1e-06, elementwise_affine=True)\n",
        "    (1): Flatten(start_dim=1, end_dim=-1)\n",
        "    (2): Linear(in_features=1536, out_features=1000, bias=True)\n",
        ")\n",
        "crop_size=[224]\n",
        "\"\"\"\n",
        "\n",
        "model = models.densenet201(weights=\"IMAGENET1K_V1\")\n",
        "\"\"\"\n",
        "(classifier): Linear(in_features=1920, out_features=1000, bias=True)\n",
        "crop_size=[224]\n",
        "\"\"\"\n",
        "\n",
        "model = models.efficientnet_v2_l(weights=\"IMAGENET1K_V1\")\n",
        "\"\"\"\n",
        "(classifier): Sequential(\n",
        "    (0): Dropout(p=0.4, inplace=True)\n",
        "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
        ")\n",
        "crop_size=[480]\n",
        "\"\"\"\n",
        "\n",
        "model = models.googlenet(weights=\"IMAGENET1K_V1\")\n",
        "\"\"\"\n",
        "(fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
        "crop_size=[384]\n",
        "\"\"\"\n",
        "\n",
        "model = models.inception_v3(weights=\"IMAGENET1K_V1\")\n",
        "\"\"\"\n",
        "(fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
        "crop_size=[299]\n",
        "\"\"\"\n",
        "\n",
        "model = models.mnasnet1_3(weights=\"IMAGENET1K_V1\")\n",
        "\"\"\"\n",
        "(classifier): Sequential(\n",
        "    (0): Dropout(p=0.2, inplace=True)\n",
        "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
        ")\n",
        "crop_size=[224]\n",
        "\"\"\"\n",
        "\n",
        "model = models.maxvit_t(weights=\"IMAGENET1K_V1\")\n",
        "\"\"\"\n",
        "(classifier): Sequential(\n",
        "    (0): AdaptiveAvgPool2d(output_size=1)\n",
        "    (1): Flatten(start_dim=1, end_dim=-1)\n",
        "    (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
        "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
        "    (4): Tanh()\n",
        "    (5): Linear(in_features=512, out_features=1000, bias=False)\n",
        ")\n",
        "crop_size=[224]\n",
        "\"\"\"\n",
        "\n",
        "model = models.mobilenet_v3_large(weights=\"IMAGENET1K_V2\")\n",
        "\"\"\"\n",
        "(classifier): Sequential(\n",
        "    (0): Linear(in_features=960, out_features=1280, bias=True)\n",
        "    (1): Hardswish()\n",
        "    (2): Dropout(p=0.2, inplace=True)\n",
        "    (3): Linear(in_features=1280, out_features=1000, bias=True)\n",
        ")\n",
        "crop_size=[224]\n",
        "\"\"\"\n",
        "\n",
        "model = models.regnet_y_128gf(weights=\"IMAGENET1K_SWAG_E2E_V1\")\n",
        "\"\"\"\n",
        "(fc): Linear(in_features=7392, out_features=1000, bias=True)\n",
        "crop_size=[384]\n",
        "\"\"\"\n",
        "\n",
        "model = models.resnext101_64x4d(weights=\"IMAGENET1K_V1\")\n",
        "\"\"\"\n",
        "(fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
        "crop_size=[224]\n",
        "\"\"\"\n",
        "\n",
        "model = models.resnet152(weights=\"IMAGENET1K_V2\")\n",
        "\"\"\"\n",
        "(fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
        "crop_size=[224]\n",
        "\"\"\"\n",
        "\n",
        "model = models.shufflenet_v2_x2_0(weights=\"IMAGENET1K_V1\")\n",
        "\"\"\"\n",
        "(fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
        "crop_size=[224]\n",
        "\"\"\"\n",
        "\n",
        "model = models.squeezenet1_1(weights=\"IMAGENET1K_V1\")\n",
        "\"\"\"\n",
        "(classifier): Sequential(\n",
        "    (0): Dropout(p=0.5, inplace=False)\n",
        "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
        "    (2): ReLU(inplace=True)\n",
        "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "  )\n",
        "crop_size=[224]\n",
        "\"\"\"\n",
        "\n",
        "model = models.swin_v2_b(weights=\"IMAGENET1K_V1\")\n",
        "\"\"\"\n",
        "(head): Linear(in_features=1024, out_features=1000, bias=True)\n",
        "crop_size=[256]\n",
        "\"\"\"\n",
        "\n",
        "model = models.vgg19_bn(weights=\"IMAGENET1K_V1\")\n",
        "\"\"\"\n",
        "(classifier): Sequential(\n",
        "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
        "    (1): ReLU(inplace=True)\n",
        "    (2): Dropout(p=0.5, inplace=False)\n",
        "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
        "    (4): ReLU(inplace=True)\n",
        "    (5): Dropout(p=0.5, inplace=False)\n",
        "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
        ")\n",
        "crop_size=[224]\n",
        "\"\"\"\n",
        "\n",
        "model = models.vit_h_14(weights=\"IMAGENET1K_SWAG_E2E_V1\")\n",
        "\"\"\"\n",
        "(heads): Sequential(\n",
        "    (head): Linear(in_features=1280, out_features=1000, bias=True)\n",
        ")\n",
        "crop_size=[518]\n",
        "\"\"\"\n",
        "\n",
        "model = models.wide_resnet101_2(weights=\"IMAGENET1K_V2\")\n",
        "\"\"\"\n",
        "(fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
        "crop_size=[224]\n",
        "\"\"\"\n",
        "```\n",
        "\n",
        "Notice, many of the models have similar output structures, but each must\n",
        "be handled slightly differently. Also, check out the printed model\n",
        "architecture of the reshaped network and make sure the number of output\n",
        "features is the same as the number of classes in the dataset."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ImsFin2V8yGz"
      },
      "source": [
        "### Load data\n",
        "\n",
        "We will use torchvision and torch.utils.data packages for loading the\n",
        "data."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "├── transfer_learning.ipynb\n",
        "└── dataset ← data dir here\n",
        "    ├── train\n",
        "    │   ├── class_1\n",
        "    │   └── class_2\n",
        "    ├── test\n",
        "    │   ├── class_1\n",
        "    └── └── class_2\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset\t\t plot\t    test_neptune.ipynb\t\t      weights\n",
            "environment.yml  README.md  test_neptune.py\n",
            "output\t\t source     transfer_learning_template.ipynb\n",
            "time: 674 ms (started: 2023-07-12 10:33:19 -05:00)\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "notebookRunGroups": {
          "groupValue": "1"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train\n",
            "Memory consumed: 0 mb\n",
            "Classes: ['class_0', 'class_1']\n",
            "Class count: 14445, 5225\n",
            "Samples: 19670\n",
            "First sample: ('dataset/train/class_0/000c076c390a4c357313fca29e390ece_left.jpg', 0)\n",
            "Class: class_0\n",
            "Image data type: <class 'PIL.Image.Image'>\n",
            "Image size: (800, 533)\n",
            "\n",
            "val\n",
            "Memory consumed: 0 mb\n",
            "Classes: ['class_0', 'class_1']\n",
            "Class count: 3612, 1306\n",
            "Samples: 4918\n",
            "First sample: ('dataset/val/class_0/00126b47d5502dfb7d01f750ad23d813_right.jpg', 0)\n",
            "Class: class_0\n",
            "Image data type: <class 'PIL.Image.Image'>\n",
            "Image size: (800, 533)\n",
            "\n",
            "time: 529 ms (started: 2023-07-12 10:22:25 -05:00)\n"
          ]
        }
      ],
      "source": [
        "# images information\n",
        "data_dir = \"dataset\"\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x)) for x in [\"train\", \"val\"]}\n",
        "\n",
        "for x in [\"train\", \"val\"]:\n",
        "    print(x)\n",
        "    mem = memory_profiler.memory_usage()[0]\n",
        "    train_dataset = image_datasets[x]\n",
        "    print(f\"Memory consumed: {memory_profiler.memory_usage()[0] - mem:.0f} mb\")\n",
        "\n",
        "    print(f\"Classes: {train_dataset.classes}\")\n",
        "    print(f\"Class count: {train_dataset.targets.count(0)}, {train_dataset.targets.count(1)}\")\n",
        "    print(f\"Samples:\",len(train_dataset))\n",
        "    print(f\"First sample: {train_dataset.samples[0]}\")\n",
        "\n",
        "    img, target = next(iter(train_dataset))\n",
        "    print(f\"Class: {train_dataset.classes[target]}\")\n",
        "    img\n",
        "\n",
        "    print(f\"Image data type: {type(img)}\")\n",
        "    print(f\"Image size: {img.size}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "notebookRunGroups": {
          "groupValue": "1"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Min/max values for each band in the image:\n",
            "    [(0, 255), (0, 253), (0, 232)]\n",
            "\n",
            "Total number of pixels for each band in the image:\n",
            "    [426400, 426400, 426400]\n",
            "\n",
            "Sum of all pixels for each band in the image:\n",
            "    [47027351.0, 39486656.0, 34987839.0]\n",
            "\n",
            "Squared sum of all pixels for each band in the image:\n",
            "    [7462613199.0, 5171815206.0, 4000350675.0]\n",
            "\n",
            "Average (arithmetic mean) pixel level for each band in the image:\n",
            "    [110.28928470919324, 92.60472795497186, 82.05403142589118]\n",
            "\n",
            "Median pixel level for each band in the image:\n",
            "    [131, 109, 99]\n",
            "\n",
            "RMS (root-mean-square) for each band in the image:\n",
            "    [132.293000888024, 110.13184157246526, 96.85910100726834]\n",
            "\n",
            "Variance for each band in the image:\n",
            "    [5337.711762293237, 3553.3868885282427, 2648.821374695073]\n",
            "\n",
            "Standard deviation for each band in the image:\n",
            "    [73.05964523793719, 59.610291800395025, 51.46670161079951]\n",
            "\n",
            "time: 5.1 ms (started: 2023-07-10 11:18:36 -05:00)\n"
          ]
        }
      ],
      "source": [
        "# get mean and std\n",
        "train_dataset = image_datasets[\"train\"]\n",
        "stat = ImageStat.Stat(img)\n",
        "\n",
        "print(\"\"\"\n",
        "Min/max values for each band in the image:\n",
        "    {.extrema}\n",
        "\n",
        "Total number of pixels for each band in the image:\n",
        "    {.count}\n",
        "\n",
        "Sum of all pixels for each band in the image:\n",
        "    {.sum}\n",
        "\n",
        "Squared sum of all pixels for each band in the image:\n",
        "    {.sum2}\n",
        "\n",
        "Average (arithmetic mean) pixel level for each band in the image:\n",
        "    {.mean}\n",
        "\n",
        "Median pixel level for each band in the image:\n",
        "    {.median}\n",
        "\n",
        "RMS (root-mean-square) for each band in the image:\n",
        "    {.rms}\n",
        "\n",
        "Variance for each band in the image:\n",
        "    {.var}\n",
        "\n",
        "Standard deviation for each band in the image:\n",
        "    {.stddev}\n",
        "\"\"\".format(*((stat, ) * 9)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "notebookRunGroups": {
          "groupValue": "1"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean: [0.4325069988595813, 0.3660265927073987, 0.35368116993918614]\n",
            "std: [0.2865084126977929, 0.23561380158258904, 0.22183923108103237]\n",
            "time: 1.96 ms (started: 2023-07-10 11:18:43 -05:00)\n"
          ]
        }
      ],
      "source": [
        "# mean and std for normalization\n",
        "max_ = stat.extrema\n",
        "mean_ = stat.mean\n",
        "std_ = stat.stddev\n",
        "\n",
        "mean = []\n",
        "std = []\n",
        "\n",
        "for k in range(len(max_)):\n",
        "    mean.append(mean_[k] / max_[k][1])\n",
        "    std.append(std_[k] / max_[k][1])\n",
        "\n",
        "print(\"mean:\", mean)\n",
        "print(\"std:\", std)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MbzVjjHI8yG0"
      },
      "source": [
        "#### Visualize a few images\n",
        "\n",
        "To-Do"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "notebookRunGroups": {
          "groupValue": ""
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://app.neptune.ai/GoTeam/Ka-GC/e/KAG-187\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 25: 100%|██████████| 25/25 [1:38:29<00:00, 236.39s/it, val, Loss: 0.4366 Acc: 0.8109]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training complete in 98m 31s\n",
            "Best val Acc: 0.813135\n",
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n",
            "Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
            "All 1 operations synced, thanks for waiting!\n",
            "Explore the metadata in the Neptune app:\n",
            "https://app.neptune.ai/GoTeam/Ka-GC/e/KAG-187/metadata\n",
            "time: 1h 42min 30s (started: 2023-07-09 22:38:51 -05:00)\n"
          ]
        }
      ],
      "source": [
        "# Top level data directory. Here we assume the format of the directory conforms\n",
        "# to the ImageFolder structure\n",
        "data_dir = \"dataset\"\n",
        "\n",
        "# Models to choose\n",
        "models_name = [\"alexnet\", \"convnext_large\", \"densenet201\",\n",
        "                \"efficientnet_v2_l\", \"googlenet\", \"inception_v3\",\n",
        "                \"mnasnet1_3\", \"maxvit_t\", \"mobilenet_v3_large\",\n",
        "                \"regnet_y_128gf\", \"resnext101_64x4d\", \"resnet152\",\n",
        "                \"shufflenet_v2_x2_0\", \"squeezenet1_1\", \"swin_v2_b\",\n",
        "                \"vgg19\", \"vit_h_14\", \"wide_resnet101_2\"]\n",
        "                \n",
        "models_name = [\"alexnet\", \"convnext_large\", \"densenet201\",\n",
        "                \"googlenet\",\n",
        "                \"mnasnet1_3\", \"maxvit_t\", \"mobilenet_v3_large\",\n",
        "                \"resnext101_64x4d\", \"resnet152\",\n",
        "                \"shufflenet_v2_x2_0\", \"squeezenet1_1\", \"swin_v2_b\",\n",
        "                \"vgg19\", \"wide_resnet101_2\"]\n",
        "\n",
        "models_name = [\"convnext_large\", \"densenet201\",\n",
        "                \"resnext101_64x4d\", \"resnet152\",\n",
        "                \"shufflenet_v2_x2_0\", \"swin_v2_b\",\n",
        "                \"wide_resnet101_2\"]\n",
        "\n",
        "models_name = [\"convnext_large\"]\n",
        "\n",
        "# number of classes in the dataset\n",
        "num_classes = 2\n",
        "\n",
        "# batch size for training (change depending on how much memory you have)\n",
        "batch_size = 12 # 8, 12, 16, 32\n",
        "\n",
        "# number of epochs to train for\n",
        "num_epochs = 25 # 20, 25, 35, 100\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n",
        "\n",
        "for option in [(\"fe\", True)]: # (\"ft\", False), (\"fe\", True) # transfer learning\n",
        "    for model_name in models_name: # models\n",
        "        for transf in [0]: # [0, 1, 2], data augmentations\n",
        "            for opti in [3]: # [0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12], optimizers\n",
        "                # Setup\n",
        "                run = neptune.init_run(\n",
        "                    project=\"GoTeam/Ka-GC\",\n",
        "                    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIwZjM0NzgxNy1lMDI1LTQxMzgtYTE2NS03OTIwOWY5NzgwNTkifQ==\",\n",
        "                )  # your credentials\n",
        "\n",
        "                \"\"\" run = neptune.init_run(\n",
        "                    project=\"GoTeam/Go-KGC\",\n",
        "                    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIwZjM0NzgxNy1lMDI1LTQxMzgtYTE2NS03OTIwOWY5NzgwNTkifQ==\",\n",
        "                )  # your credentials \"\"\"\n",
        "\n",
        "                run[\"sys/tags\"].add(option[0])\n",
        "                run[\"sys/tags\"].add(\"transf {}\".format(transf))\n",
        "\n",
        "                # Init model\n",
        "                model, input_size = initialize_model(model_name, num_classes, feature_extract=option[1])\n",
        "                model = model.to(device)\n",
        "\n",
        "                # data augmentation\n",
        "                data_transforms = get_data_transforms(transf, input_size)\n",
        "                # data_transforms = get_data_transforms(transf, input_size, mean=mean, std=std)\n",
        "\n",
        "                image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in [\"train\", \"val\"]}\n",
        "\n",
        "                # option 1: dataloaders with WeightedRandomSampler\n",
        "                \"\"\" \n",
        "                run[\"sys/tags\"].add(\"WRS\")\n",
        "                train_dataset = image_datasets[\"train\"]\n",
        "                targets = torch.tensor(train_dataset.targets, dtype=torch.int8)\n",
        "                class_counts = torch.bincount(targets)\n",
        "                # weights = 1.0 / class_counts.float()\n",
        "                weights = [1 / class_counts[i].float() for i in targets]\n",
        "                sampler = WeightedRandomSampler(weights, len(train_dataset), replacement=True)\n",
        "\n",
        "                dataloaders = {}\n",
        "                for x in [\"train\", \"val\"]:\n",
        "                    if x == \"train\":\n",
        "                        dataloaders[x] = torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, sampler=sampler,\n",
        "                                                                    shuffle=False, drop_last=False, num_workers=4)\n",
        "                    else: \n",
        "                        dataloaders[x] = torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
        "                                                                    shuffle=True, drop_last=False, num_workers=4) \"\"\"\n",
        "                \n",
        "                # option 2: dataloaders with ImbalancedDatasetSampler\n",
        "                \"\"\" \n",
        "                run[\"sys/tags\"].add(\"IDS\")\n",
        "                dataloaders = {}\n",
        "                for x in [\"train\", \"val\"]:\n",
        "                    if x == \"train\":\n",
        "                        dataloaders[x] = torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, sampler=ImbalancedDatasetSampler(train_dataset),\n",
        "                                                                    shuffle=False, drop_last=False, num_workers=4)\n",
        "                    else: \n",
        "                        dataloaders[x] = torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
        "                                                                    shuffle=True, drop_last=False, num_workers=4) \"\"\"\n",
        "\n",
        "                # option 3: dataloaders without WeightedRandomSampler and ImbalancedDatasetSampler\n",
        "                dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
        "                                                                shuffle=True, drop_last=False, num_workers=4) for x in [\"train\", \"val\"]}\n",
        "                            \n",
        "                dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"val\"]}\n",
        "                class_names = image_datasets[\"train\"].classes\n",
        "     \n",
        "                # Hyperparameters\n",
        "                criterion = nn.CrossEntropyLoss() # nn.BCELoss() # nn.CrossEntropyLoss()\n",
        "\n",
        "                # observe that all parameters are being optimized\n",
        "                optimizer = get_optimizer(model, opti)\n",
        "\n",
        "                # decay LR by a factor of 0.1 every 7 epochs\n",
        "                exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "                parameters = {\n",
        "                    \"model\": model_name,\n",
        "                    \"classes\": num_classes,\n",
        "                    # \"epochs\": num_epochs,\n",
        "                    \"batch size\": batch_size,\n",
        "                    \"criterion\": \"CrossEntropyLoss\",\n",
        "                    \"optimazer\": type(optimizer).__name__,\n",
        "                    \"lr\": optimizer.param_groups[0][\"lr\"]\n",
        "                }\n",
        "                run[\"params\"] = parameters\n",
        "\n",
        "                #---\n",
        "                # Train\n",
        "                model, \\\n",
        "                train_losses, \\\n",
        "                val_losses, \\\n",
        "                train_accuracies, \\\n",
        "                val_accuracies = train_model(run, model, device, dataloaders, dataset_sizes, \n",
        "                                            criterion, optimizer, exp_lr_scheduler, num_epochs=num_epochs)\n",
        "                # save model\n",
        "                # torch.save(model.state_dict(), \"weights/{}_{}_transf{}\".format(model_name, option[0], trans))\n",
        "                torch.save(model, \"weights/{}_{}_transf{}_{}_{}_{}_{}.pt\".format(parameters[\"model\"], option[0],\n",
        "                                                                                 transf, parameters[\"optimazer\"], num_epochs,\n",
        "                                                                                 parameters[\"batch size\"], parameters[\"lr\"]))\n",
        "\n",
        "                # Evaluation\n",
        "                for data in [\"train\", \"val\"]:\n",
        "                    labels, predictions, predictions_proba = get_predictions(model, dataloaders, data)\n",
        "                    auc = roc_auc_score(labels, predictions_proba[:, 1])\n",
        "                    run[\"{}/auc\".format(data)] = auc\n",
        "                \n",
        "                run.stop()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dCym4iWAf0_g"
      },
      "source": [
        "## Prepared test data to Kaggle"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7P-Yyo94GOJT"
      },
      "source": [
        "#### Read test image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "BL8XjSW2gCEH",
        "outputId": "8fbfa649-8b8b-478b-946b-a9ad2658435e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c74d97b01eae257e44aa9d5bade97baf_left</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c74d97b01eae257e44aa9d5bade97baf_right</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70efdf2ec9b086079795c442636b55fb_left</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>70efdf2ec9b086079795c442636b55fb_right</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1f0e3dad99908345f7439f8ffabdffc4_left</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10533</th>\n",
              "      <td>e261790d3a4cb0c69c17d7c183830289_right</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10534</th>\n",
              "      <td>d21137447f7fdc47f7e6677ae35522a7_left</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10535</th>\n",
              "      <td>d21137447f7fdc47f7e6677ae35522a7_right</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10536</th>\n",
              "      <td>ec2951e5afb60d72a4a3e0be6d3e9c0a_left</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10537</th>\n",
              "      <td>ec2951e5afb60d72a4a3e0be6d3e9c0a_right</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10538 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           ID  score\n",
              "0       c74d97b01eae257e44aa9d5bade97baf_left      0\n",
              "1      c74d97b01eae257e44aa9d5bade97baf_right      0\n",
              "2       70efdf2ec9b086079795c442636b55fb_left      0\n",
              "3      70efdf2ec9b086079795c442636b55fb_right      0\n",
              "4       1f0e3dad99908345f7439f8ffabdffc4_left      0\n",
              "...                                       ...    ...\n",
              "10533  e261790d3a4cb0c69c17d7c183830289_right      0\n",
              "10534   d21137447f7fdc47f7e6677ae35522a7_left      0\n",
              "10535  d21137447f7fdc47f7e6677ae35522a7_right      0\n",
              "10536   ec2951e5afb60d72a4a3e0be6d3e9c0a_left      0\n",
              "10537  ec2951e5afb60d72a4a3e0be6d3e9c0a_right      0\n",
              "\n",
              "[10538 rows x 2 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 25.4 ms (started: 2023-07-09 22:26:36 -05:00)\n"
          ]
        }
      ],
      "source": [
        "df_test = pd.read_csv(\"source/sample.csv\")\n",
        "df_test"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Get probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "time: 1.9 s (started: 2023-07-09 22:27:05 -05:00)\n"
          ]
        }
      ],
      "source": [
        "model_name = \"convnext_large\"\n",
        "option = \"fe\"\n",
        "transf = 0\n",
        "optimazer = \"AdamW\"\n",
        "lr = 0.001\n",
        "epochs = 25\n",
        "batch_size = 12\n",
        "input_size = 224\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "model = torch.load(\"weights/{}_{}_transf{}_{}_{}_{}_{}.pt\".format(model_name, option, transf, optimazer, epochs, batch_size, lr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 1.83 ms (started: 2023-07-09 22:27:13 -05:00)\n"
          ]
        }
      ],
      "source": [
        "data_transforms = get_data_transforms(transf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10538it [02:42, 64.71it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[0.0207, 0.9793],\n",
              "        [0.0035, 0.9965],\n",
              "        [0.8226, 0.1774],\n",
              "        ...,\n",
              "        [0.7469, 0.2531],\n",
              "        [0.9045, 0.0955],\n",
              "        [0.9154, 0.0846]], device='cuda:0')"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 2min 42s (started: 2023-07-09 22:27:18 -05:00)\n"
          ]
        }
      ],
      "source": [
        "y_prob = []\n",
        "\n",
        "for index, row in tqdm(df_test.iterrows()):\n",
        "    img_path = \"source/test/{}.jpg\".format(row[\"ID\"])\n",
        "\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "\n",
        "    img = Image.open(img_path)\n",
        "    img = data_transforms[\"val\"](img)\n",
        "    img = img.unsqueeze(0)\n",
        "    img = img.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(img)\n",
        "        \n",
        "        # _, preds = torch.max(outputs, 1)\n",
        "        preds = torch.nn.functional.softmax(outputs, dim=-1)\n",
        "        # print(pred)\n",
        "        y_prob.append(preds)\n",
        "\n",
        "        model.train(mode=was_training)\n",
        "y_prob = torch.cat(y_prob, dim=0)\n",
        "y_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c74d97b01eae257e44aa9d5bade97baf_left</td>\n",
              "      <td>0.979291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c74d97b01eae257e44aa9d5bade97baf_right</td>\n",
              "      <td>0.996499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70efdf2ec9b086079795c442636b55fb_left</td>\n",
              "      <td>0.177402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>70efdf2ec9b086079795c442636b55fb_right</td>\n",
              "      <td>0.361335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1f0e3dad99908345f7439f8ffabdffc4_left</td>\n",
              "      <td>0.127075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10533</th>\n",
              "      <td>e261790d3a4cb0c69c17d7c183830289_right</td>\n",
              "      <td>0.326341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10534</th>\n",
              "      <td>d21137447f7fdc47f7e6677ae35522a7_left</td>\n",
              "      <td>0.066853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10535</th>\n",
              "      <td>d21137447f7fdc47f7e6677ae35522a7_right</td>\n",
              "      <td>0.253099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10536</th>\n",
              "      <td>ec2951e5afb60d72a4a3e0be6d3e9c0a_left</td>\n",
              "      <td>0.095472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10537</th>\n",
              "      <td>ec2951e5afb60d72a4a3e0be6d3e9c0a_right</td>\n",
              "      <td>0.084584</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10538 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           ID     score\n",
              "0       c74d97b01eae257e44aa9d5bade97baf_left  0.979291\n",
              "1      c74d97b01eae257e44aa9d5bade97baf_right  0.996499\n",
              "2       70efdf2ec9b086079795c442636b55fb_left  0.177402\n",
              "3      70efdf2ec9b086079795c442636b55fb_right  0.361335\n",
              "4       1f0e3dad99908345f7439f8ffabdffc4_left  0.127075\n",
              "...                                       ...       ...\n",
              "10533  e261790d3a4cb0c69c17d7c183830289_right  0.326341\n",
              "10534   d21137447f7fdc47f7e6677ae35522a7_left  0.066853\n",
              "10535  d21137447f7fdc47f7e6677ae35522a7_right  0.253099\n",
              "10536   ec2951e5afb60d72a4a3e0be6d3e9c0a_left  0.095472\n",
              "10537  ec2951e5afb60d72a4a3e0be6d3e9c0a_right  0.084584\n",
              "\n",
              "[10538 rows x 2 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 165 ms (started: 2023-07-09 22:30:22 -05:00)\n"
          ]
        }
      ],
      "source": [
        "score = [h.cpu().numpy().tolist() for h in y_prob]\n",
        "score = np.array(score)[:, 1]\n",
        "\n",
        "df_test[\"score\"] = score\n",
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 41.4 ms (started: 2023-07-09 22:30:28 -05:00)\n"
          ]
        }
      ],
      "source": [
        "# save\n",
        "from datetime import datetime\n",
        "\n",
        "# datetime object containing current date and time\n",
        "now = datetime.now()\n",
        "dt_string = now.strftime(\"%d-%m-%Y-%H:%M:%S\")\n",
        "\n",
        "df_test.to_csv(\"output/{}_{}_{}_transf{}_{}_{}_{}_{}.csv\".format(dt_string, model_name, option, transf, optimazer, epochs, batch_size, lr), sep=\",\", index=False, header=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "1RAC0vLJGeNg",
        "cRArdThPIurA",
        "PG4HUYFv8yG3",
        "eEcgQfkyONkm"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
